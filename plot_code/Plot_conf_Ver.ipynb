{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7664dbde",
   "metadata": {},
   "source": [
    "# DProvDB Experimental Evaluation\n",
    "\n",
    "We would like to understand DProvDB's performance via empirical study.\n",
    "\n",
    "## End-to-end Comparison\n",
    "\n",
    "First we would like to perform an end-to-end comparison of DProvDB against baseline systems.\n",
    "\n",
    "We have the following baselines:\n",
    "\n",
    "- DProvDB minus additiveGM (Vanilla mechanism in our paper)\n",
    "- Chorus\n",
    "- DProvDB minus cached views (i.e., enabling Chorus with Provenance table)\n",
    "- Simulating PrivateSQL \n",
    "\n",
    "Note that the key idea in PrivateSQL is to generate synopses for pre-determined views and answer queries using synopses.\n",
    "The overall privacy budget is split to generate the synopses in advance.\n",
    "One prominent way to allocate budget to views, as mentioned in PrivateSQL paper, is fair allocation.\n",
    "That is to split the budget w.r.t the sensitivity of the views s.t. the expected error on each view is the same.\n",
    "Since PrivateSQL system is not open source, we use our system with a specific setting to simulate PrivateSQL.\n",
    "\n",
    "Each experiment is run for 4 times, we plot the mean and the variance as evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load package and fonts\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font=\"Helvetica\", rc={\"figure.figsize\":(4, 3)})\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 1.75})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2495397",
   "metadata": {},
   "source": [
    "1) RRQ, over Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "report = pd.read_csv('../data/RRQ_adult_end_to_end.csv', sep=';')\n",
    "\n",
    "report = report.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "report.columns = report.columns.str.strip()\n",
    "\n",
    "\n",
    "# processing list strings\n",
    "\n",
    "def parse_list(s):\n",
    "    if isinstance(s, str) and s.startswith('List'):\n",
    "        return [float(x) for x in s[5: -1].split(\",\")]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "report = report.applymap(parse_list)\n",
    "\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"baseline\"), \"mechanism\"] = \"PrivateSQL\"\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"PrivateSQL\"), \"viewConstraintFlag\"] = \"dynamic fixed-normalized: 1.0\"\n",
    "\n",
    "report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281626d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data\n",
    "\n",
    "mechanism_mapping = {\"aGM\": \"DProvDB\", \"baseline\": \"Vanilla\", \"Chorus\": \"Chorus\", \"ChorusP\": \"ChorusP\", \"PrivateSQL\": \"sPrivateSQL\"}\n",
    "\n",
    "epsilon_mapping = {0.4: \"$\\epsilon=0.4$\", 0.8: \"$\\epsilon=0.8$\", 1.6: \"$\\epsilon=1.6$\", 3.2: \"$\\epsilon=3.2$\", 6.4: \"$\\epsilon=6.4$\"}\n",
    "\n",
    "def processing_data(df, dataset, task, metric, workload_size, constraint_setting = \"dynamic fixed: 1.0\", mech_dt = [\"aGM\", \"baseline\", \"PrivateSQL\", \"Chorus\", \"ChorusP\"]):\n",
    "    \n",
    "    filtered_df = df[(df[\"dataset\"]==dataset) & (df[\"task\"]==task)]\n",
    "            \n",
    "    ret_dt = {}\n",
    "\n",
    "    for mech in mech_dt:\n",
    "                \n",
    "        for eps in sorted(set(filtered_df['budget'])):\n",
    "            \n",
    "            filtered_df_eps = filtered_df[filtered_df['budget']==eps]\n",
    "            \n",
    "            if metric == \"utility\" or metric == \"DCFG\":\n",
    "                ret_dt[(mechanism_mapping[mech], epsilon_mapping[eps])] = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][metric].values)\n",
    "            elif metric == \"nDCFG\":\n",
    "                DCFG = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"DCFG\"].values)\n",
    "                utility = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"utility\"].values)\n",
    "                ret_dt[(mechanism_mapping[mech], epsilon_mapping[eps])] = [i / j  for i, j in zip(DCFG, utility)]\n",
    "            elif metric == \"utilization\":\n",
    "                accountant = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"accountant\"].values)\n",
    "                budget = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"budget\"].values)\n",
    "                ret_dt[(scenario_mapping[case], epsilon_mapping[eps])] = [i / j for i, j in zip(accountant, budget)]\n",
    "    \n",
    "    return ret_dt\n",
    "\n",
    "\n",
    "# test\n",
    "# processing_data(pd.concat([report.iloc[:960], report.iloc[2881:]]), \"adult\", \"RRQ_round-robin\", \"utility\", 8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fab32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "\n",
    "# get data\n",
    "adult_rr_utility = processing_data(report, \"adult\", \"RRQ_round-robin\", \"utility\", 20000)\n",
    "adult_r_utility = processing_data(report, \"adult\", \"RRQ_random\", \"utility\", 20000)\n",
    "\n",
    "adult_rr_fairness = processing_data(report, \"adult\", \"RRQ_round-robin\", \"nDCFG\", 20000)\n",
    "adult_r_fairness = processing_data(report, \"adult\", \"RRQ_random\", \"nDCFG\", 20000)\n",
    "\n",
    "sns.set(font=\"Helvetica\", rc={\"figure.figsize\":(4, 3)})\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 3})\n",
    "\n",
    "# drawing figures\n",
    "fig, axes = plt.subplots(ncols=4,figsize=(19, 3))\n",
    "print(adult_rr_utility)\n",
    "\n",
    "data = pd.Series(adult_rr_utility).reset_index()\n",
    "data.columns = ['mechanisms', 'epsilons', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "line = sns.lineplot(data=data, x='epsilons', y='utility', hue='mechanisms', linewidth=1.5, ax=axes[0], style=\"mechanisms\", markers=True, markersize=12, dashes=True)\n",
    "sns.move_legend(axes[0], \"lower center\", bbox_to_anchor=(2.2, 1), ncol=5, title=\"Mechanisms\", frameon=True, markerscale=2.3, fontsize=13, title_fontsize=15)\n",
    "axes[0].set(ylabel=\"#queries being answered\")\n",
    "\n",
    "\n",
    "\n",
    "data = pd.Series(adult_r_utility).reset_index()\n",
    "data.columns = ['mechanisms', 'epsilons', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "sns.lineplot(data=data, x='epsilons', y='utility', hue='mechanisms', linewidth=1.5, ax=axes[1], legend=False, style=\"mechanisms\", markers=True, markersize=12, dashes=True)\n",
    "axes[1].set(ylabel=None)\n",
    "\n",
    "hatches = ['/', '..', 'xx', '\\\\', '|']\n",
    "\n",
    "data = pd.Series(adult_rr_fairness).reset_index()\n",
    "data.columns = ['mechanisms', 'epsilons', 'nDCFG']\n",
    "data = data.explode(\"nDCFG\")\n",
    "sns.boxplot(data=data, x='mechanisms', y='nDCFG', linewidth=1.5, ax=axes[2])\n",
    "axes[2].set_xticklabels([\"DProvDB\", \"Vanilla\", \"PrivateSQL\", \"Chorus\", \"ChorusP\"], fontsize=10)\n",
    "patches = [patch for patch in axes[2].patches if type(patch) == mpl.patches.PathPatch]\n",
    "h = hatches * (len(patches) // len(hatches))\n",
    "for patch, hatch in zip(patches, h):\n",
    "#     patch.set_hatch(hatch)\n",
    "    fc = patch.get_facecolor()\n",
    "    patch.set_edgecolor(fc)\n",
    "    patch.set_facecolor('none')\n",
    "\n",
    "\n",
    "data = pd.Series(adult_r_fairness).reset_index()\n",
    "data.columns = ['mechanisms', 'epsilons', 'nDCFG']\n",
    "data = data.explode(\"nDCFG\")\n",
    "sns.boxplot(data=data, x='mechanisms', y='nDCFG', linewidth=1.5, ax=axes[3])\n",
    "axes[3].set(ylabel=None)\n",
    "axes[3].set_xticklabels([\"DProvDB\", \"Vanilla\", \"PrivateSQL\", \"Chorus\", \"ChorusP\"], fontsize=10)\n",
    "patches = [patch for patch in axes[3].patches if type(patch) == mpl.patches.PathPatch]\n",
    "h = hatches * (len(patches) // len(hatches))\n",
    "for patch, hatch in zip(patches, h):\n",
    "#     patch.set_hatch(hatch)\n",
    "    fc = patch.get_facecolor()\n",
    "    patch.set_edgecolor(fc)\n",
    "    patch.set_facecolor('none')\n",
    "\n",
    "\n",
    "plt.savefig('end_to_end.pdf', dpi=600, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f989165",
   "metadata": {},
   "source": [
    "The above 4 figs: *a) utility (#queries being answered) v.s. epsilon, round-robin; b) utility (#queries being answered) v.s. epsilon, randomized; c) fairness (nDCFG) v.s. epsilon, round-robin; d) fairness (nDCFG) v.s. epsilon, randomized.*\n",
    "\n",
    "\n",
    "**Round-robin** means data analysts submit queries in a round-robin manner.\n",
    "**Randomized** means data analysts submit queries in a randomized manner.\n",
    "\n",
    "The experiment is evaluated with only 2 data analysts.\n",
    "\n",
    "For **Utility**, we use the number of queries are answered in total as the metric. For **Fairness**, we use the normalized DCFG (nDCFG) as the evaluation metric.\n",
    "We would like to capture the relationship between the data analysts' privilege level and the individual utility.\n",
    "Thus we coin DCFG, which is an entropy-related metric that gets higher when the data analyst's utility is positively proportionaly to their privilege level.\n",
    "Note that DCFG is naturally higher when the overall utility for a mechanism is higher than another.\n",
    "The nDCFG metric normalizes the DCFG by the total number of queries being answered by this mechanism.\n",
    "\n",
    "Takeaway messages from this experiment:\n",
    "1) DProvDB outperforms all competing systems, in both round-robin and randomized scenarios;\n",
    "2) With **only 2** data analysts, additive Gaussian mechanism performs marginally better than baseline mechanism;\n",
    "3) Enabling the provenance table (and setting row constraints) can improve fairness among data analysts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dea6ef",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "Here are some hypotheses, w.r.t different components in DProvDB, that we would like to empirically verify.\n",
    "\n",
    "### Hypothesis 1 (Additive GM). Given the same overall privacy budget, DProvDB with additiveGM performs better than with baseline mechanism in terms of utility.\n",
    "\n",
    "AdditiveGM enables the method that reuse the same global synopsis to generate local synopsis when different data analysts ask a similar or same query. Using additiveGM the system should have more queries being answered than using baseline mechanism.\n",
    "*More particularly, we would like to verify how the utility gap between two mechanisms changes when the number of data analysts increases in the system.*\n",
    "\n",
    "In this experiment, all data analysts have the same privilege level. We increase the number of data analysts from 1 to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "report = pd.read_csv('../data/RRQ_adult_analyst_constraints.csv', sep=';')\n",
    "\n",
    "report = report.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "report.columns = report.columns.str.strip()\n",
    "\n",
    "\n",
    "# processing list strings\n",
    "\n",
    "def parse_list(s):\n",
    "    if isinstance(s, str) and s.startswith('List'):\n",
    "        return [float(x) for x in s[5: -1].split(\",\")]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "report = report.applymap(parse_list)\n",
    "\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"baseline\"), \"mechanism\"] = \"PrivateSQL\"\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"PrivateSQL\"), \"viewConstraintFlag\"] = \"dynamic fixed-normalized: 1.0\"\n",
    "\n",
    "report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e790531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data\n",
    "mechanism_mapping = {\"aGM\": \"DProvDB\", \"baseline\": \"Vanilla\"}\n",
    "\n",
    "analysts = [2, 3, 4, 5, 6]\n",
    "\n",
    "epsilon = 3.2\n",
    "\n",
    "epsilon_mapping = {0.8: \"$\\epsilon=0.8$\", 1.6: \"$\\epsilon=1.6$\", 3.2: \"$\\epsilon=3.2$\", 6.4: \"$\\epsilon=6.4$\"}\n",
    "\n",
    "constraint_setting = {\"dynamic fixed-aGM: 1.0\": \"-l_max\", \"dynamic fixed-normalized: 1.0\": \"-l_sum\"}\n",
    "\n",
    "def processing_data_aGM(df, dataset, task, epsilonOrAnalyst = \"a\"):\n",
    "    \n",
    "    filtered_df = df[(df[\"dataset\"]==dataset) & (df[\"task\"]==task)]\n",
    "            \n",
    "    ret_dt = {}\n",
    "                \n",
    "    if (epsilonOrAnalyst == \"a\"):\n",
    "        for analyst in analysts:\n",
    "\n",
    "            filtered_df_eps = filtered_df[(filtered_df['analystConstraints'].map(len)==analyst) & (filtered_df['budget']==epsilon)]\n",
    "\n",
    "            ret_dt[(\"DProvDB-l_max\", analyst)] = list(filtered_df_eps[(filtered_df_eps['mechanism']==\"aGM\") & (filtered_df_eps['viewConstraintFlag']==\"dynamic fixed-aGM: 1.0\")]['utility'].values)\n",
    "            ret_dt[(\"DProvDB-l_sum\", analyst)] = list(filtered_df_eps[(filtered_df_eps['mechanism']==\"aGM\") & (filtered_df_eps['viewConstraintFlag']==\"dynamic fixed-normalized: 1.0\")]['utility'].values)\n",
    "            ret_dt[(\"Vanilla-l_sum\", analyst)] = list(filtered_df_eps[(filtered_df_eps['mechanism']==\"baseline\") & (filtered_df_eps['viewConstraintFlag']==\"dynamic fixed-normalized: 1.0\")]['utility'].values)\n",
    "\n",
    "    elif (epsilonOrAnalyst == \"e\"):\n",
    "        for eps in epsilon_mapping.keys():\n",
    "            filtered_df_eps = filtered_df[(filtered_df['analystConstraints'].map(len)==2) & (filtered_df['budget']==eps)]\n",
    "            \n",
    "            ret_dt[(\"DProvDB-l_max\", epsilon_mapping[eps])] = list(filtered_df_eps[(filtered_df_eps['mechanism']==\"aGM\") & (filtered_df_eps['viewConstraintFlag']==\"dynamic fixed-aGM: 1.0\")]['utility'].values)\n",
    "            ret_dt[(\"DProvDB-l_sum\", epsilon_mapping[eps])] = list(filtered_df_eps[(filtered_df_eps['mechanism']==\"aGM\") & (filtered_df_eps['viewConstraintFlag']==\"dynamic fixed-normalized: 1.0\")]['utility'].values)\n",
    "            ret_dt[(\"Vanilla-l_sum\", epsilon_mapping[eps])] = list(filtered_df_eps[(filtered_df_eps['mechanism']==\"baseline\") & (filtered_df_eps['viewConstraintFlag']==\"dynamic fixed-normalized: 1.0\")]['utility'].values)\n",
    "\n",
    "            \n",
    "    return ret_dt\n",
    "\n",
    "\n",
    "# test\n",
    "# processing_data_aGM(report.iloc[897:2881], \"adult\", \"RRQ_round-robin\", \"utility\", 4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "\n",
    "# get data\n",
    "adult_a_utility = processing_data_aGM(report, \"adult\", \"RRQ_round-robin\", \"a\")\n",
    "adult_e_utility = processing_data_aGM(report, \"adult\", \"RRQ_round-robin\", \"e\")\n",
    "\n",
    "# print(adult_a_utility)\n",
    "\n",
    "hatches = ['//', '-\\-', '|||']\n",
    "sns.set(font=\"Helvetica\", rc={\"figure.figsize\":(4, 3)})\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1.75})\n",
    "\n",
    "# drawing figures\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 3))\n",
    "\n",
    "data = pd.Series(adult_a_utility).reset_index()\n",
    "data.columns = ['mechanisms', 'analysts', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='analysts', y='utility', hue='mechanisms', ax=axes[0], )\n",
    "axes[0].set(ylabel=\"#queries being answered\")\n",
    "axes[0].set(xlabel=\"#analysts ($\\epsilon=3.2$)\")\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "# get container objects for each hue category\n",
    "containers = bar.containers\n",
    "\n",
    "# create legend handles\n",
    "handles = []\n",
    "for container in containers:\n",
    "    for rect in container:\n",
    "        handles.append(rect)\n",
    "sns.move_legend(axes[0], \"lower center\", bbox_to_anchor=(1.1, 1), ncol=3, title=\"Mechanisms\", frameon=True, handles=containers, )\n",
    "\n",
    "\n",
    "\n",
    "data = pd.Series(adult_e_utility).reset_index()\n",
    "data.columns = ['mechanisms', 'eps', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='eps', y='utility', hue='mechanisms', ax=axes[1], )\n",
    "axes[1].set(ylabel=\"#queries being answered\")\n",
    "axes[1].set(xlabel=\"epsilon\")\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].legend_.remove()\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('agm.pdf', dpi=600, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb11b55",
   "metadata": {},
   "source": [
    "The above 4 figs: *a) utility (#queries being answered) v.s. #analysts, round-robin; b) utility (#queries being answered) v.s. #analysts, randomized; c) utilization rate v.s. #analysts, round-robin; d) utilization rate v.s. #analysts, randomized.*\n",
    "\n",
    "Utilization rate: the overall privacy budget utilization after the execution of the entire workload &mdash; defined as $\\frac{\\text{privacy accountant}}{\\text{overall budget}}$;\n",
    "\n",
    "\n",
    "Takeaway messages:\n",
    "1) The utlity gap between DProvDB (aGM) and DProvDB (baseline) grows with the increase of the number of data analysts;\n",
    "2) DProvDB (aGM) can potentially answer more queries when the number of data analysts grows;\n",
    "3) In this experiments, the average utilization rate of DProvDB (aGM) is lower than baseline, suggesting that DProvDB better saves privacy budgets in executing this query workload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c647046",
   "metadata": {},
   "source": [
    "### Hypothesis 2 (Cached Views/Synopses). Given the same overall privacy budget, mechanisms using cached views/synopses outperform those without caches in terms of utility, when the size of query workload increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "report = pd.read_csv('../data/RRQ_adult_increasing_workload.csv', sep=';')\n",
    "\n",
    "report = report.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "report.columns = report.columns.str.strip()\n",
    "\n",
    "\n",
    "# processing list strings\n",
    "\n",
    "def parse_list(s):\n",
    "    if isinstance(s, str) and s.startswith('List'):\n",
    "        return [float(x) for x in s[5: -1].split(\",\")]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "report = report.applymap(parse_list)\n",
    "\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"baseline\"), \"mechanism\"] = \"PrivateSQL\"\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"PrivateSQL\"), \"viewConstraintFlag\"] = \"dynamic fixed-normalized: 1.0\"\n",
    "\n",
    "report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data\n",
    "mechanism_mapping = {\"aGM\": \"DProvDB\", \"baseline\": \"Vanilla\", \"Chorus\": \"Chorus\", \"ChorusP\": \"ChorusP\"}\n",
    "\n",
    "workloads = [50, 400, 1000, 2000, 4000, 7000]\n",
    "\n",
    "epsilon_mapping = {0.4: \"$\\epsilon=0.4$\", 0.8: \"$\\epsilon=0.8$\", 1.6: \"$\\epsilon=1.6$\", 3.2: \"$\\epsilon=3.2$\"}\n",
    "\n",
    "def processing_data_caches(df, dataset, task, metric, number_of_analysts, eps, constraint_setting = \"dynamic fixed: 1.0\"):\n",
    "    \n",
    "    filtered_df = df[(df[\"dataset\"]==dataset) & (df[\"task\"]==task) & (df[\"budget\"]==eps) & (df[\"viewConstraintFlag\"]==constraint_setting)]\n",
    "            \n",
    "    ret_dt = {}\n",
    "\n",
    "    for mech in mechanism_mapping.keys():\n",
    "                \n",
    "        for workload_size_per_analyst in workloads:\n",
    "            \n",
    "            workload_size = number_of_analysts * workload_size_per_analyst\n",
    "            \n",
    "            filtered_df_eps = filtered_df[(filtered_df['totalNoOfQueries']==workload_size)]\n",
    "            \n",
    "            if metric == \"utility\" or metric == \"DCFG\":\n",
    "                ret_dt[(mechanism_mapping[mech], workload_size)] = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][metric].values)\n",
    "            elif metric == \"nDCFG\":\n",
    "                DCFG = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"DCFG\"].values)\n",
    "                utility = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"utility\"].values)\n",
    "                ret_dt[(mechanism_mapping[mech], workload_size)] = [i / j for i, j in zip(DCFG, utility)]\n",
    "            elif metric == \"utilization\":\n",
    "                accountant = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"accountant\"].values)\n",
    "                budget = list(filtered_df_eps[filtered_df_eps['mechanism']==mech][\"budget\"].values)\n",
    "                ret_dt[(mechanism_mapping[mech], workload_size)] = [i / j for i, j in zip(accountant, budget)]\n",
    "    \n",
    "    return ret_dt\n",
    "\n",
    "\n",
    "# test\n",
    "# processing_data_caches(report.iloc[:897], \"adult\", \"RRQ_round-robin\", \"utility\", 2, 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc552ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "\n",
    "report_caches = report.iloc[:960]\n",
    "\n",
    "# get data\n",
    "adult_rr_utility_04 = processing_data_caches(report_caches, \"adult\", \"RRQ_round-robin\", \"utility\", 2, 0.4)\n",
    "adult_r_utility_04 = processing_data_caches(report_caches, \"adult\", \"RRQ_random\", \"utility\", 2, 0.4)\n",
    "\n",
    "adult_rr_utility_08 = processing_data_caches(report_caches, \"adult\", \"RRQ_round-robin\", \"utility\", 2, 0.8)\n",
    "adult_r_utility_08 = processing_data_caches(report_caches, \"adult\", \"RRQ_random\", \"utility\", 2, 0.8)\n",
    "\n",
    "adult_rr_utility_16 = processing_data_caches(report_caches, \"adult\", \"RRQ_round-robin\", \"utility\", 2, 1.6)\n",
    "adult_r_utility_16 = processing_data_caches(report_caches, \"adult\", \"RRQ_random\", \"utility\", 2, 1.6)\n",
    "\n",
    "adult_rr_utility_32 = processing_data_caches(report_caches, \"adult\", \"RRQ_round-robin\", \"utility\", 2, 3.2)\n",
    "adult_r_utility_32 = processing_data_caches(report_caches, \"adult\", \"RRQ_random\", \"utility\", 2, 3.2)\n",
    "\n",
    "adult_rr_utility_64 = processing_data_caches(report_caches, \"adult\", \"RRQ_round-robin\", \"utility\", 2, 6.4)\n",
    "adult_r_utility_64 = processing_data_caches(report_caches, \"adult\", \"RRQ_random\", \"utility\", 2, 6.4)\n",
    "\n",
    "# adult_rr_utilization_04 = processing_data_fairness(report_caches, \"adult\", \"RRQ_round-robin\", \"utilization\", 2, 0.4)\n",
    "# adult_r_utilization_04 = processing_data_fairness(report_caches, \"adult\", \"RRQ_random\", \"utilization\", 2, 0.4)\n",
    "\n",
    "hatches = ['//', '-\\-', '|||', 'x']\n",
    "sns.set(font=\"Helvetica\", rc={\"figure.figsize\":(4, 3)})\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.6, rc={\"lines.linewidth\": 1.75})\n",
    "\n",
    "\n",
    "# drawing figures\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(23.5, 3))\n",
    "\n",
    "data = pd.Series(adult_rr_utility_04).reset_index()\n",
    "data.columns = ['mechanisms', 'workloads', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='workloads', y='utility', hue='mechanisms', ax=axes[0], )\n",
    "# sns.move_legend(axes[0], \"lower center\", bbox_to_anchor=(2.8, 1), ncol=4, title=\"Mechanisms\", frameon=True,)\n",
    "axes[0].set(ylabel=\"#queries being answered\")\n",
    "axes[0].set(xlabel=None)\n",
    "# axes[0].set_xticklabels([])\n",
    "# axes[0].legend_.remove()\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "# get container objects for each hue category\n",
    "containers = bar.containers\n",
    "\n",
    "# create legend handles\n",
    "handles = []\n",
    "for container in containers:\n",
    "    for rect in container:\n",
    "        handles.append(rect)\n",
    "sns.move_legend(axes[0], \"lower center\", bbox_to_anchor=(2.8, 1), ncol=4, title=\"Mechanisms\", frameon=True, handles=containers, fontsize=17, title_fontsize=17)\n",
    "\n",
    "\n",
    "data = pd.Series(adult_rr_utility_08).reset_index()\n",
    "data.columns = ['mechanisms', 'workloads', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='workloads', y='utility', hue='mechanisms', ax=axes[1], )\n",
    "axes[1].set(ylabel=\"#queries being answered\")\n",
    "axes[1].set(xlabel=None, ylabel=None)\n",
    "# axes[1].set_xticklabels([])\n",
    "axes[1].legend_.remove()\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "    \n",
    "\n",
    "data = pd.Series(adult_rr_utility_16).reset_index()\n",
    "data.columns = ['mechanisms', 'workloads', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='workloads', y='utility', hue='mechanisms', ax=axes[2], )\n",
    "axes[2].set(ylabel=\"#queries being answered\")\n",
    "axes[2].set(xlabel=None, ylabel=None)\n",
    "# axes[2].set_xticklabels([])\n",
    "axes[2].legend_.remove()\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "data = pd.Series(adult_rr_utility_32).reset_index()\n",
    "data.columns = ['mechanisms', 'workloads', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='workloads', y='utility', hue='mechanisms', ax=axes[3], )\n",
    "axes[3].set(ylabel=\"#queries being answered\")\n",
    "axes[3].set(xlabel=None, ylabel=None)\n",
    "# axes[3].set_xticklabels([])\n",
    "axes[3].legend_.remove()\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "data = pd.Series(adult_rr_utility_64).reset_index()\n",
    "data.columns = ['mechanisms', 'workloads', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='workloads', y='utility', hue='mechanisms', ax=axes[4], )\n",
    "axes[4].set(ylabel=\"#queries being answered\")\n",
    "axes[4].set(xlabel=None, ylabel=None)\n",
    "# axes[4].set_xticklabels([])\n",
    "axes[4].legend_.remove()\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "\n",
    "plt.savefig('cached.pdf', dpi=600, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e64ee7",
   "metadata": {},
   "source": [
    "Above: Round-robin, utility vs. size of workload, epsilon = 0.4, 0.8, 1.6, 3.2, 6.4\n",
    "\n",
    "Below: Randomized, utility vs. size of workload, epsilon = 0.4, 0.8, 1.6, 3.2, 6.4\n",
    "\n",
    "\n",
    "\n",
    "Takeaway messages:\n",
    "1) Due to the use of cached views/synopses, the number of queries being answered increases with the increasing size of workload, if we fix the overall privacy budget.\n",
    "2) This is observed for all settings with privacy budget in [0.4, 0.8, 1.6, 3.2, 6.4]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b8dc7",
   "metadata": {},
   "source": [
    "### Hypothesis 3 (Fairness Constraints). If we allow an expansion parameter $\\tau \\geq 1$, we can trade off fairness for better utility.\n",
    "\n",
    "We evaluate this experiment with DProvDB with additiveGM.\n",
    "We fix the analyst setting to be the same 2 data analysts, and change the ways we set the analyst constraints in the provenance table.\n",
    "Note that the parameter $\\tau$ controls the multiplier to the analyst constraints.\n",
    "\n",
    "We compare amongst the following scenarios:\n",
    "- Statical (pre-determined) analyst and view constraints &rarr; label \"static\".\n",
    "- Statical analyst constraint proportionally to their privileges, dynamic view constraints &rarr; label \"$\\tau=1$\".\n",
    "- Statical analyst constraint proportionally to their privileges (multiplied 1.3), dynamic view constraints &rarr; label \"$\\tau=1.3$\".\n",
    "- Statical analyst constraint proportionally to their privileges (multiplied 1.6), dynamic view constraints &rarr; label \"$\\tau=1.6$\".\n",
    "- Statical analyst constraint proportionally to their privileges (multiplied 1.9), dynamic view constraints &rarr; label \"$\\tau=1.9$\".\n",
    "\n",
    "Remark: When $\\tau=1$, the scenario is in fact the DProvDB system we evaluate in the end-to-end comparision experiments.\n",
    "\n",
    "**Evaluation Metrics:** \n",
    "1) Utility: the number of total queries being answered;\n",
    "2) Utilization rate: the overall privacy budget utilization after the execution of the entire workload &mdash; defined as $\\frac{\\text{privacy accountant}}{\\text{overall budget}}$;\n",
    "3) Fairness: nDCFG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e966c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "report = pd.read_csv('../data/RRQ_adult_fairness.csv', sep=';')\n",
    "\n",
    "report = report.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "report.columns = report.columns.str.strip()\n",
    "\n",
    "\n",
    "# processing list strings\n",
    "\n",
    "def parse_list(s):\n",
    "    if isinstance(s, str) and s.startswith('List'):\n",
    "        return [float(x) for x in s[5: -1].split(\",\")]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "report = report.applymap(parse_list)\n",
    "\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"baseline\"), \"mechanism\"] = \"PrivateSQL\"\n",
    "report.loc[(report[\"viewConstraintFlag\"] == \"static fixed-normalized: 1.0\") & (report[\"mechanism\"] == \"PrivateSQL\"), \"viewConstraintFlag\"] = \"dynamic fixed-normalized: 1.0\"\n",
    "\n",
    "report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1010673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data\n",
    "\n",
    "scenario_mapping = {\"static fixed: 1.0\": \"static\", \"dynamic fixed: 1.0\": \"$\\tau=1$\", \"dynamic fixed-expansion: 1.3\": \"$\\tau=1.3$\", \"dynamic fixed-expansion: 1.6\": \"$\\tau=1.6$\", \"dynamic fixed-expansion: 1.9\": \"$\\tau=1.9$\"}\n",
    "\n",
    "epsilon_mapping = {0.4: \"$\\epsilon=0.4$\", 0.8: \"$\\epsilon=0.8$\", 1.6: \"$\\epsilon=1.6$\", 3.2: \"$\\epsilon=3.2$\"}\n",
    "\n",
    "def processing_data_fairness(df, dataset, task, metric, workload_size = 8000, mech = \"aGM\"):\n",
    "    \n",
    "    filtered_df = df[(df[\"dataset\"]==dataset) & (df[\"task\"]==task) & (df[\"totalNoOfQueries\"]==workload_size) & (df[\"mechanism\"]==mech)]\n",
    "            \n",
    "    ret_dt = {}\n",
    "\n",
    "    for case in scenario_mapping.keys():\n",
    "                \n",
    "        for eps in epsilon_mapping.keys():\n",
    "            \n",
    "            filtered_df_eps = filtered_df[filtered_df['budget']==eps]\n",
    "            \n",
    "            if metric == \"utility\" or metric == \"DCFG\":\n",
    "                ret_dt[(scenario_mapping[case], epsilon_mapping[eps])] = list(filtered_df_eps[filtered_df_eps['viewConstraintFlag']==case][metric].values)\n",
    "            elif metric == \"nDCFG\":\n",
    "                DCFG = list(filtered_df_eps[filtered_df_eps['viewConstraintFlag']==case][\"DCFG\"].values)\n",
    "                utility = list(filtered_df_eps[filtered_df_eps['viewConstraintFlag']==case][\"utility\"].values)\n",
    "                ret_dt[(scenario_mapping[case], epsilon_mapping[eps])] = [i / j for i, j in zip(DCFG, utility)]\n",
    "            elif metric == \"utilization\":\n",
    "                accountant = list(filtered_df_eps[filtered_df_eps['viewConstraintFlag']==case][\"accountant\"].values)\n",
    "                budget = list(filtered_df_eps[filtered_df_eps['viewConstraintFlag']==case][\"budget\"].values)\n",
    "                ret_dt[(scenario_mapping[case], epsilon_mapping[eps])] = [i / j for i, j in zip(accountant, budget)]\n",
    "                \n",
    "    \n",
    "    return ret_dt\n",
    "\n",
    "\n",
    "# test\n",
    "# processing_data_fairness(pd.concat([report.iloc[:960], report.iloc[2881:]]), \"adult\", \"RRQ_round-robin\", \"utilization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "\n",
    "# report_truncate = pd.concat([report.iloc[:896], report.iloc[1569:]])\n",
    "report_fairness_vs_utility = pd.concat([report.iloc[:960], report.iloc[2881:]])\n",
    "\n",
    "# get data\n",
    "adult_rr_utility = processing_data_fairness(report_fairness_vs_utility, \"adult\", \"RRQ_round-robin\", \"utility\", 8000)\n",
    "adult_r_utility = processing_data_fairness(report_fairness_vs_utility, \"adult\", \"RRQ_random\", \"utility\", 8000)\n",
    "\n",
    "adult_rr_utilization = processing_data_fairness(report_fairness_vs_utility, \"adult\", \"RRQ_round-robin\", \"utilization\", 8000)\n",
    "adult_r_utilization = processing_data_fairness(report_fairness_vs_utility, \"adult\", \"RRQ_random\", \"utilization\", 8000)\n",
    "\n",
    "adult_rr_fairness = processing_data_fairness(report_fairness_vs_utility, \"adult\", \"RRQ_round-robin\", \"nDCFG\", 8000)\n",
    "adult_r_fairness = processing_data_fairness(report_fairness_vs_utility, \"adult\", \"RRQ_random\", \"nDCFG\", 8000)\n",
    "\n",
    "\n",
    "hatches = ['\\\\', '//', '|||', 'x.']\n",
    "sns.set(font=\"Helvetica\", rc={\"figure.figsize\":(4, 3)})\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.6, rc={\"lines.linewidth\": 1.75})\n",
    "\n",
    "# drawing figures\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(11, 7.5))\n",
    "\n",
    "data = pd.Series(adult_rr_utility).reset_index()\n",
    "data.columns = ['scenarios', 'epsilons', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='scenarios', y='utility', hue='epsilons', ax=axes[0][0], )\n",
    "axes[0][0].set(ylabel=\"#queries being answered\")\n",
    "axes[0][0].set_xticklabels([])\n",
    "axes[0][0].set(xlabel=None)\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "# get container objects for each hue category\n",
    "containers = bar.containers\n",
    "\n",
    "# create legend handles\n",
    "handles = []\n",
    "for container in containers:\n",
    "    for rect in container:\n",
    "        handles.append(rect)\n",
    "sns.move_legend(axes[0][0], \"lower center\", bbox_to_anchor=(1.1, 1), ncol=4, title=\"Epsilons\", frameon=True, handles=containers, fontsize=17, title_fontsize=19)\n",
    "# sns.move_legend(axes[0][0], \"lower center\", bbox_to_anchor=(1, 1), ncol=4, title=\"Epsilons\", frameon=True,)\n",
    "\n",
    "\n",
    "data = pd.Series(adult_r_utility).reset_index()\n",
    "data.columns = ['scenarios', 'epsilons', 'utility']\n",
    "data = data.explode(\"utility\")\n",
    "bar = sns.barplot(data=data, x='scenarios', y='utility', hue='epsilons', ax=axes[0][1], )\n",
    "axes[0][1].set(ylabel=None)\n",
    "axes[0][1].set_xticklabels([])\n",
    "axes[0][1].legend_.remove()\n",
    "axes[0][1].set(xlabel=None)\n",
    "patches = [patch for patch in bar.patches]\n",
    "h = [hatches[i//(len(patches) // len(hatches))] for i in range(len(patches))]\n",
    "for patch, hatch in zip(patches, h):\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "\n",
    "\n",
    "PROPS = {\n",
    "    'boxprops':{'facecolor':'none', 'edgecolor':'gray'},\n",
    "    'medianprops':{'color':'black'},\n",
    "    'whiskerprops':{'color':'black'},\n",
    "    'capprops':{'color':'gray'}\n",
    "}\n",
    "    \n",
    "data = pd.Series(adult_rr_fairness).reset_index()\n",
    "data.columns = ['scenarios', 'epsilons', 'nDCFG']\n",
    "data = data.explode(\"nDCFG\")\n",
    "sns.boxplot(data=data, x='scenarios', y='nDCFG', linewidth=1.5, ax=axes[1][0], **PROPS)\n",
    "axes[1][0].set_xticklabels([\"static\", r\"$\\tau=1$\", r\"$\\tau=1.3$\", r\"$\\tau=1.6$\", r\"$\\tau=1.9$\"])\n",
    "# axes[2][0].set(xlabel=None)\n",
    "# patches = [patch for patch in axes[1][0].patches if type(patch) == mpl.patches.PathPatch]\n",
    "# h = hatches * (len(patches) // 5)\n",
    "# for patch, hatch in zip(patches, h):\n",
    "# #     patch.set_hatch(hatch)\n",
    "#     fc = patch.get_facecolor()\n",
    "#     patch.set_edgecolor(fc)\n",
    "#     patch.set_facecolor('none')\n",
    "\n",
    "    \n",
    "data = pd.Series(adult_r_fairness).reset_index()\n",
    "data.columns = ['scenarios', 'epsilons', 'nDCFG']\n",
    "data = data.explode(\"nDCFG\")\n",
    "sns.boxplot(data=data, x='scenarios', y='nDCFG', linewidth=1.5, ax=axes[1][1], **PROPS)\n",
    "axes[1][1].set_xticklabels([\"static\", r\"$\\tau=1$\", r\"$\\tau=1.3$\", r\"$\\tau=1.6$\", r\"$\\tau=1.9$\"])\n",
    "axes[1][1].set(ylabel=None)\n",
    "# patches = [patch for patch in axes[1][1].patches if type(patch) == mpl.patches.PathPatch]\n",
    "# h = hatches * (len(patches) // 5)\n",
    "# for patch, hatch in zip(patches, h):\n",
    "# #     patch.set_hatch(hatch)\n",
    "#     fc = patch.get_facecolor()\n",
    "#     patch.set_edgecolor(fc)\n",
    "#     patch.set_facecolor('none')\n",
    "\n",
    "fig.align_ylabels()\n",
    "\n",
    "\n",
    "plt.savefig('fairness.pdf', dpi=600, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b2307",
   "metadata": {},
   "source": [
    "These experiments are done with RRQ workload (of size 4000 * 2). The first row of the figures corresponds to the case that data analysts ask queries in a round-robin manner, while in the experiments with the second row analysts randomly ask queries.\n",
    "\n",
    "Takeaway messages from the experiments:\n",
    "1) Dynamically setting view constraints helps in answering more queries, better utlizing privacy budgets, and achieving better fairness scores;\n",
    "2) Increasing the constraint expansion parameter $\\tau$ can result in answering more queries. A relative large gap in utility gain can be observed from graudating setting $\\tau=1$ to $1.9$, for all epsilons.\n",
    "3) A possible reason, as can be observed from the plots in the middle column, for the utility gain, might be that setting an expanded constraint help better utilize the privacy budgets.\n",
    "4) The price of getting higher utility by setting larger $\\tau$ is sacrificing proportional fairness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
